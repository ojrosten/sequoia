<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.6"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Sequoia: The Testing Framework</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Sequoia
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.6 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title">The Testing Framework </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>The <code>sequoia</code> testing framework is designed for <a class="el" href="../../dc/d92/testframeworkpage.html#sec_scale">scale</a> and is <a class="el" href="../../dc/d92/testframeworkpage.html#sec_platform">platform-independent</a>, <a class="el" href="../../dc/d92/testframeworkpage.html#sec_automated">highly automated</a>, <a class="el" href="../../dc/d92/testframeworkpage.html#sec_robustness">robust</a>, <a class="el" href="../../dc/d92/testframeworkpage.html#sec_extensible">extensible</a>, <a class="el" href="../../dc/d92/testframeworkpage.html#sec_malleable">malleable</a>, <a class="el" href="../../dc/d92/testframeworkpage.html#sec_semantics">semantics-aware</a>, <a class="el" href="../../dc/d92/testframeworkpage.html#sec_allocators">allocator-aware</a>, <a class="el" href="../../dc/d92/testframeworkpage.html#sec_generics">generics-friendly</a> and <a class="el" href="../../dc/d92/testframeworkpage.html#sec_expressive">expressive</a>.</p>
<h1><a class="anchor" id="sec_scale"></a>
Scalability</h1>
<p>To operate effectively at scale, <code>sequoia</code> incorporates the following features:</p><ul>
<li>No waste: if a principled structure is adhered to, then running with the <code>prune</code> option will ensure that only those tests dependent on changes since the last run will be executed. Changes may be either to source files or materials exploited by the test. In particular:<ol type="1">
<li>cpp files should supply definitions only for the header of the same name;</li>
<li>Given a test file <code>Tests/Foo/Bar.cpp</code>, any testing materials should be stored in <code>TestMaterials/Foo/Bar</code>.</li>
</ol>
</li>
<li>Concurrency: by default, tests run concurrently. Tests are grouped into families and, by default, concurrency will be at the family level if there are more than three families; otherwise, concurrency is at the level of individual tests. However, this may be overridden using <code>--async-depth</code>.</li>
<li>Instability detection: <code>locate-instabilities</code> is called with an integer, specifying the number of times tests should be run. Instabilities are pinned down to the line of test code where they first manifest. By default, everything is run within the same program, allowing detection of changes to static data. However, it's conceivable that these changes are desired. If appropriate, use the <code>--sandbox</code> flag to ensure that each run is done in an independent process.</li>
</ul>
<h1><a class="anchor" id="sec_platform"></a>
Platform Independence</h1>
<p>Having cloned the <code>sequoia</code> repository, the testing framework may be built with CMake. A good way to get started is to navigate to the <code>TestFrameworkDiagnostics</code> folder and invoke CMake with the appropriate generator. This has been tested with MSVC, clang and gcc. Appropriate commands may look something like </p><pre>
cmake -G "Visual Studio 17 2022" -B ..\build\CMade\win\TestFrameworkDiagnostics
</pre><p> or </p><pre>
cmake -D CMAKE_CXX_COMPILER=/usr/local/opt/llvm/bin/clang++ -B ../build/CMade/clang/TestFrameworkDiagnostics
</pre><p> depending on the system and precise set-up. Invoking the resulting executable runs a minimal set of diagnostics. A richer set may be found in <code>TestAll</code>.</p>
<p>As described in more detail below, certain output arising from running tests is written to files which should be placed under version control. This presents additional difficulties in guaranteeing platform independence. For example, the files may contain absolute paths or demangled type names, which could differ from machine to machine and/or platform to platform. For files placed under version control this is particularly problematic. Therefore, various mechanisms have been put in place to mitigate these problems: see <a class="el" href="../../dc/d92/testframeworkpage.html#sec_robustness">Robustness</a>, <a class="el" href="../../dc/d92/testframeworkpage.html#sec_malleable">Malleability</a> and <a class="el" href="../../dc/d92/testframeworkpage.html#sec_generics">Generics-Friendliness</a>.</p>
<h1><a class="anchor" id="sec_automated"></a>
Automation</h1>
<p>The processes of initializing a new project, and creating new tests are highly automated. Both are integrated with CMake. For example, running with the command line arguments</p>
<pre>
    init "Jo Bloggs" "Some/Absolute/Path" "\t"
</pre><p>will do the following:</p><ol type="1">
<li>Create a new project in the specified location, with tabs preferred to spaces, and with the copyright of any new material created though mechanisms described below belonging to Jo Bloggs.</li>
<li>Invoke <code>CMake</code> to build the new project.</li>
<li>Initialize a new <code>git</code> repository and add the newly created project files.</li>
</ol>
<p>Additionally, on Windows:</p><ol type="1">
<li>Visual Studio will be launched, with the appropriate start-up project set.</li>
<li>The new project's (empty) test suite will be run.</li>
</ol>
<p>Once a new project has been created, it is natural to add code and tests. This can all be done automatically by utilizing the <code>create</code> mode which will add the appropriate files, amend the <code>CMakeLists.txt</code> files and run CMake.</p>
<h1><a class="anchor" id="sec_robustness"></a>
Robustness</h1>
<p>The testing framework is sophisticated and sophistication brings danger, since it raises the chances that the framework itself has bugs. If this is the case, then the framework would give clients a false sense of security about the code they have written, which could be disastrous. To mitigate this risk, the testing framework has been designed to run self-diagnostics. This has been employed to give a high degree of confidence that the existing framework is correct. Used idiomatically, it should confer similar confidence in any extensions.</p>
<p>One of the defining features of the testing framework is that it is designed to expose false-positives. As such, each test operates in a particular <a class="el" href="../../d5/d05/TestLogger_8hpp.html#test_mode_enum">test_mode</a>, chosen at compile time: standard, false_positive and false_negative.</p>
<p>In standard mode, the test framework operates as one might expect. A typical check looks as follows:</p>
<pre>
check(equality, "Description of test", x, 5);
</pre><p>If <code>x==5</code> the check passes, whereas if <code>x!=5</code> a failure is reported. However, suppose that <code>check</code> has a bug. For example, it might never report failure. To counter this, tests can be created to be run in false-positive mode. In this case, the above example will pass when <code>x!=5</code> and fail when <code>x==5</code>. The purpose of this is to pick up bugs in the testing framework itself.</p>
<p>In standard mode, when a test fails, details of the failure will be given directly to the client. In the above example, for the case where <code>x==4</code>, something like this will be seen:</p>
<pre>
Obtained : 4
Predicted: 5
</pre><p>In false-positive mode, this output is not made directly visible to the user, since the false-positive test has succeeded. Instead, it is dumped to a file. This means that clients can check whether the underlying failure which the false-positive check has detected is as expected. It is good practice to place this file under version control. This provides sensitivity both to changes in the false-positive test and also changes to the way in which the testing framework generates output.</p>
<p>Clients may extend the testing framework to conveniently test their types, for example by specializing the <a class="el" href="../../df/d6f/structsequoia_1_1testing_1_1value__tester.html#value_tester_primary">value_tester</a> (see <a class="el" href="../../dc/d92/testframeworkpage.html#sec_extensible">Extensibility</a>). This is a perfect opportunity to write some false-positive tests to give confidence that the newly-added code is not spuriously reporting success.</p>
<p>Finally, there are false-negative tests. They are essentially the same as standard mode tests; however, they are treated separately since statements like</p>
<pre>
check(equality, "Description of test", 5, 5);
</pre><p>are morally tests of the testing framework itself, rather than tests of client code. As with false-positive tests, output is dumped to an auxiliary file, primarily as a means of detecting (via version control) changes to the way the testing framework generates output.</p>
<p>Just as the outputs of false-negative and, especially, false-positive tests is written to files, so to is the output from exception checks. For example, consider the call</p>
<pre>
check_exception_thrown&lt;std::runtime_error&gt;("Description", f);
</pre><p>where <code>f</code> is invocable without any arguments. This check will pass if <code>f</code> throws an exception of the expected type - here, <code>std::runtime_error</code>. To obtain higher fidelity, the message associated with the exception is written to a file, again best placed under version control. First and foremost, this allows clients to check that the exception thrown is the one expected. After all, it may be that <code>f</code> can fail in a number of says, each with the same exception type. Only by checking the associated message can one be sure that the failure is the one intended to be tested. Secondly, by placing the file under version control, changes to either the text of the exception, or changes to which exception was actually thrown can be detected.</p>
<p>There are cases where an exception message may differ between platforms. For example, consider the case where an exception is thrown reporting that a file, specified by an absolute path, does not exist. Since this is written to a file placed under version control, without mitigation running the associated test on different platforms will generate unwanted diffs. To mitigate this, <code>check_exception_thrown</code> comes with an optional final argument: a function object which post-processes the exception message, prior to writing to disk.</p>
<p>Should the need arise, the class template <a class="el" href="../../d5/d02/structsequoia_1_1testing_1_1exception__message__extractor.html#exception_message_extractor_primary">exception_message_extractor</a> is provided to allow customized extraction of error messages from exceptions of arbitrary types.</p>
<h1><a class="anchor" id="sec_extensible"></a>
Extensibility</h1>
<p>There are several ways in which the testing framework may be extended. Suppose that a client has created a new type, <code>my_type</code>. One way or another, it is almost inevitable that calls will be made to <code>check</code>. If the type is sufficiently simple, and defines <code>operator==</code>, it suffices for clients to specialize the class template <a class="el" href="../../d6/d39/structsequoia_1_1testing_1_1serializer.html#serializer_primary">serializer</a>. This defines how to serialize instances of the class and so we may again end up with a failure report along the lines of the above. However, if the class is more complex, there is a superior alternative.</p>
<p><code>sequoia</code> defines a class template, <a class="el" href="../../df/d6f/structsequoia_1_1testing_1_1value__tester.html#value_tester_primary">value_tester</a>. One purpose of this is to provide a customization point where the <code>const</code> accessors of two instances of a class can be used to probe purported equality. Suppose that a client has created a new container and consider comparing two instances. <code>operator==</code> may return <code>false</code> or <code>true</code>. In the first case, we want to get to the bottom of this, in a more appropriate manner than simply serializing the class (which may produce excessive output). For a container, it would make sense compare the size and then to use iterators to compare the elements and find any that differ. However, it is worth doing this even if <code>operator==</code> returns <code>true</code>; after all, the aim is to test with high fidelity and it may be that <code>operator==</code> has a bug; or perhaps it is fine but there's a bug in the <code>const</code> accessors. Either way, a well designed definition of the static method</p>
<pre>
void value_tester&lt;my_type&gt;::check(equality_check_t, std::string_view description, const my_type&amp; obtained, const my_type&amp; prediction);
</pre><p>will catch these potential inconsistencies.</p>
<p>However, there is a gap here. Consider the the first time a type is instantiated in a test, say</p>
<pre>
my_type x{5};
</pre><p>It is desirable to check that <code>x</code> is correctly initialized, but circular to write something like</p>
<pre>
check(equality, "x correctly initialized", x, my_type{5});
</pre><p>Therefore, in addition to supplying a static <code>check(equality_check_t, ...)</code> method, we can supply an overload, <code>check(equivalence_check_t, ...)</code>.Suppose that, in this example, <code>my_type</code> simply wraps an <code>int</code>. In this case we would define the static method</p>
<pre>
void value_tester&lt;my_type&gt;::check(equivalence_check_t, std::string_view description, const my_type&amp; obtained, int prediction);
</pre><p>which will automatically be called when the following line of code is invoked:</p>
<pre>
check(equivalence, "x correctly initialized", x, 5);
</pre><p>There are circumstances in which it appropriate to consider equivalence of a type not with another type, but with itself. For example, consider <code>std::filesystem::path</code>. Equality of two instances would amount to the paths being identical. One reasonable definition of two equivalent paths is that they point to a filesystem object with the same name and the same contents, but potentially in different locations. This is the convention used by <code>sequoia</code>.</p>
<p>In some circumstances, it may feel more logically comfortable check weak equivalence instead of equivalence (done in the obvious way, adhering to the pattern above). For example, suppose the goal is to compare two values of <code>std::fuction&lt;R (Args...)&gt;</code>. Statically, it is known that the signatures are the same. However, at runtime, all that can be readily checked is whether a given <code>std::function</code> is null or not. Therefore, it may be reasonable to say that two instances of <code>std::fuction&lt;R (Args...)&gt;</code> are weakly equivalent if they are either both null or both not null.</p>
<p>There is also an entirely different way in which the testing framework may be extended. The <a class="el" href="../../d8/d58/conceptsequoia_1_1testing_1_1extender.html#checker_primary">checker</a> class template provides basic functionality such as <code>check(equality_check_t, ...)</code> and <code>check_exception_thrown</code>. However, the class template accepts a variadic number of extenders, which enhance its functionality. Examples provided with <code>sequoia</code> are various semantics extenders (see below), and a <a class="el" href="../../d6/d92/classsequoia_1_1testing_1_1performance__extender.html#performance_extender_primary">performance_extender</a>. Extenders may be readily mixed and matched with appropriate using declarations, some of which are supplied with the library.</p>
<p>So far, the customization discussed is static, or type-based. Generally, wherever this is possible, it is to be preferred. However, the framework does support dynamic customization, which can be understood by the following example. Recall that equivalence of instances of <code>std::filesystem::path</code> is taken to mean that two filesystem objects, potentially in different locations, have the same name and the same contents. By default, the contents of a file are determined via de-serialization to a string. However, this may not be appropriate for all file types. Moreover, the particular file types involved in comparisons will only be known at runtime and so are dynamic, as opposed to static. With this in mind, the testing framework supports generalized (weak) equivalence checks. Statically, these facilitate the injection of an arbitrary type which is fed through to the <code>value_tester</code>, providing dynamic customizations.</p>
<h1><a class="anchor" id="sec_semantics"></a>
Semantics-Awareness</h1>
<p>By utilizing <code>sequoia</code>'s testing framework, clients are strongly encouraged to think carefully about the semantics of their classes upfront, rather than as an after-thought. For the purposes of this library, a type exhibiting regular semantics is understood to exhibit copy/move constructors, copy/move assignment, <code>operator==</code>, <code>operator!=</code> and swap. Note that there is no strict requirement for a default constructor. If a class provides this functionality, then the <a class="el" href="../../d9/daf/RegularTestCore_8hpp.html#regular_test_alias">regular_test</a> alias template may be utilized, which makes use of the <a class="el" href="../../d4/d5d/classsequoia_1_1testing_1_1regular__extender.html#regular_extender_primary">regular_extender</a> class template. The latter provides an overload of <code>check_semantics</code>: given two instantiations of a class it checks consistency of the above list of special member functions / functions. Alternatively, for move-only types (defined as regular types but for which the copy operations are removed), the <a class="el" href="../../de/d25/MoveOnlyTestCore_8hpp.html#move_only_test_alias">move_only_test</a> may be exploited. Either way, this removes much of the burden of devising ways to carefully check consistency of these operations by reliably bundling everything into a call to check_semantics.</p>
<p>As a bonus, if both serialization and de-serialization are defined, <code>check_semantics</code> will check their consistency. Not a single line of extra code need to written to activate the extra check: static reflection determines whether or not it should be performed.</p>
<h1><a class="anchor" id="sec_malleable"></a>
Malleability</h1>
<p>For some tests it is desirable to utilize auxiliary materials, as alluded to in <a class="el" href="../../dc/d92/testframeworkpage.html#sec_scale">Scalability</a>. Given a test file <code>Tests/Foo/Bar.cpp</code>, any testing materials should be stored in <code>TestMaterials/Foo/Bar</code>, using the following conventions. First, if the materials are simply for consumption by the test code, the materials can simply be placed in the aforementioned directory. However, it may be that it is desirable to perform a comparison with materials stored on disk. In this case, there are three sub-folders with special names: <code>Auxiliary</code>, <code>WorkingCopy</code> and <code>Prediction</code>, of which only the last is necessary. When a test is run that possesses a <code>Prediction</code> folder, the <code>Auxiliary</code> and <code>WorkingCopy</code> folders, should they exist, are copied to a temporary location which is cleared out at the beginning of each test run. If <code>WorkingCopy</code> does not exist, it is created on the fly. At some point during the test, the contents of <code>WorkingCopy</code> should be compared with <code>Prediction</code>; the test framework comes with methods exposing the relevant paths. The <code>Auxiliary</code> folder is useful for holding materials never intended for comparison. Roughly speaking, differences between the <code>WorkingCopy</code> and <code>Prediction</code> folders and any files they may hold will be reported as a test failure.</p>
<p>However, there are some exceptions to this. First, the following files are ignored: <code>.keep</code> and <code>.DS_Store</code>. More interestingly, clients may specify that particular substrings within a file are ignored when comparing file contents. To motivate this, consider end-to-end testing of the testing framework itself. The output includes timings, of the form <code>[2ms]</code>. The problem is that timings can be expected to change, meaning that a given test may regularly fail in way which is not useful. To counter this, each file in <code>Prediction</code> and it subfolders can be supplemented by a file of the same name but with the extension <code>seqpat</code>. The latter is expected to contain a list of regular expressions, specifying sub-strings to be ignored from the file comparison process.</p>
<p>Suppose now that we are left we a genuine failure after preprocessing the files in <code>WorkingCopy</code> and <code>Prediction</code>. It may be that the code under test is actually correct, but the predictions need updating. This can be achieved by running the test with the additional argument <code>update</code>. Updating is discerning: only files exhibiting a failure after preprocessing are updated. This prevents the version-controlled diffs being polluted with noise.</p>
<h1><a class="anchor" id="sec_allocators"></a>
Allocator-Awareness</h1>
<p>The C++17 allocator framework is powerful but complex. Much of this complexity derives from the intersection of the logical abstraction containers seek to represent with the realities of creating efficient code. Consider <code>std::vector</code>. This models dynamic, contiguous storage: the logical content of this container is its elements. Indeed, <code>operator==</code> checks that two vectors are of the same size and that its elements are equal, but no more than this. However, vectors additionally comprise allocators which are not part of the logical abstraction. In principle, the allocator maybe stateful and this raises interesting questions. Should <code>operator==</code> take account of this state? The design of <code>std::vector</code> gives a definitive answer: No. But what should be done when doing assignment? Should the state of the allocator propagate or not. Should the choice be consistent between copy assignment and move assignment? What about swapping? There are no definitive answers to these questions and so this is left in the hands of the client. Indeed, <code>std::allocator_traits</code> exposes various type definitions, reflecting this freedom.</p>
<p>With flexibility of the C++ allocation model comes commensurate difficulty when it comes to testing. To help with this, the <code>sequoia</code> testing framework has been built with allocators firmly in mind. An allocator-aware class with regular semantics may be rigorously tested by using a <a class="el" href="../../da/dcc/classsequoia_1_1testing_1_1regular__allocation__extender.html#regular_allocation_extender_primary">regular_allocation_extender</a>; for the move-only case <a class="el" href="../../d7/d8c/classsequoia_1_1testing_1_1move__only__allocation__extender.html#move_only_allocation_extender_primary">move_only_allocation_extender</a> is available. These checkers provides an overload of the check_semantics method which accepts allocation predictions. In the regular case, the latter correspond to copying, assigning (with and without propagation) and mutation, together with para-copy/move. Here and throught the documentation para copy/move refer to the copy-like and move-like constructors which additionally accept an allocator. The design accommodates scoped allocators and multiple allocators (be each of them normal or scoped). <a class="el" href="../../d8/da2/RegularAllocationTestCore_8hpp.html#regular_allocation_test_alias">Regular allocation tests</a> come with a facility for automatically generating all 8 combinations of allocation propagation from a single call to <code>check_semantics</code>. <a class="el" href="../../d3/d67/MoveOnlyAllocationTestCore_8hpp.html#move_only_allocation_test_alias">Move-only allocation tests</a> do likewise for the 4 combinations relevant to move-only types.</p>
<p>An additional subtlety arises from attempting to ensure independence on library implementations and build settings. This is sharpened by the fact that certain operations on the standard containers perform additional allocations in an MSVC debug build, compared to a release build. However, the framework is flexible enough to deal with this. Indeed, if the semantics are such that the container under inspection behaves like a container of values, then the framework automatically shifts the user-supplied allocation predictions to compensate. If, instead, it behaves like a container of pointers, then a line of code registering this fact is sufficient. If the behaviour does not fit into either of these categories, then the framework is flexible enough for clients to specify their own solutions.</p>
<p>The allocation testing framework has been rigorously tested with a combination of false-positive and false-negative checks and has very high fidelity. For example, if <code>check_semantics</code> is fed instances of an allocating type for which <code>operator==</code> has accidentally been written such that one (or both) of its arguments are captured by value, rather than by reference, the framework will detect this.</p>
<h1><a class="anchor" id="sec_generics"></a>
Generics-Friendliness</h1>
<p>When writing generic code, it is natural to want to test it with a variety of appropriate types. This leads to the idea of templated unit tests; within <code>sequoia</code> this is most naturally achieved by leaving the test classes plain (rather than templated) but templating various methods inside. However, a challenge with doing this is interpreting failures. The line at which the failure occurs is no longer enough to uniquely disambiguate, since this line may correspond to several different template instantiations.</p>
<p>Consequently, <code>sequoia</code> reports failures with plenty of type information. For example, the following output is typical of what to expect when checking the equality of two instances of <code>std::pair&lt;int,double&gt;</code>:</p>
<pre>
Tests/TestFramework/UnitTestDiagnostics.cpp, Line 51
[std::pair&lt;int, double&gt;]
operator== returned false

Second element of pair is incorrect
[double]
operator== returned false
Obtained : 7.8
Predicted: -7.8
</pre><p>For each sub-check performed as part of the top-level check, type information is reported. This is generated by the class template <a class="el" href="../../d3/d78/structsequoia_1_1testing_1_1type__demangler.html#type_demangler_primary">type_demangler</a>. Clients are welcome to specialize this to provide more readable demangling. Note that the built-in demangling strives to standardize the demangling from MSVC, clang and gcc. This ensures that when type information is written to files under version control, these files are stable under changes of platform.</p>
<p>There is another side to generics-friendliness. Consider the example of testing a class template. Following the examples above, it makes sense to start by testing (weak) equivalence following initialization and then subsequently performing equality checks of two instances following various operations. However, given this type is templated, it may be that the type with which it is instantiated does not naturally support equality checks. For example, consider <code>std::pair&lt;int, std::function&lt;void ()&gt;</code>. Here, the first member supports equality checking but the second only weak equivalence checking. However, the implementation of <code>value_tester</code> for <code>std::pair</code> supplied by <code>sequoia</code> is such that it supports the following call:</p>
<pre>
check(with_best_available, "", x, y);
</pre><p>where <code>x</code> and <code>y</code> are both instances of <code>std::pair&lt;int, std::function&lt;void ()&gt;</code>. Static reflection is used to invoke the strongest check for each of the wrapped type.</p>
<h1><a class="anchor" id="sec_expressive"></a>
Expressiveness</h1>
<p>The focus of the testing framework's API is on providing useful primitives, such as <code>check_semantics</code>, <code>check_exception_thrown</code> and <code>check</code>. As discussed above, the latter naturally forms overload sets which allows generic testing of class templates, even where the class is heterogeneous and the types with which it is instantiated may support checks of differing strengths. Clients are encouraged to supply each check with a description, which constitutes the second argument. In addition, there is the facility to provide customized advice in the event of particular failures. For example, within the allocation testing framework, it is possible for a negative number of allocations to be reported. This is rather counter-intuitive and, when encountered for the first time, may raise doubts as to the correctness of the framework. This is hopefully ameliorated by leveraging the advice functionality internally, giving typical output:</p>
<pre>
Obtained : -1
Predicted: 1
Advice   : A negative allocation count generally indicates an allocator propagating when it shouldn't or not propagating when it should.
</pre><p>Clients may provided customized advice by calling many of the check methods with an extra function object bound to an instance of the <a class="el" href="../../d6/d71/classsequoia_1_1testing_1_1tutor.html#tutor_primary">tutor</a> class template. If <code>operator()</code> is overloaded in such a way that it takes two instances of a type and returns a string, then reflection is utilized to apply this function object whenever the appropriate overload may be invoked. For example, consider the case where a function object is supplied to provide advice for <code>int</code>s, under certain conditions. Suppose this function object is fed to a check performed on a <code>std::vector&lt;int&gt;</code>. In this case, the function object will be propagated internally until it reaches the point where it can be invoked on the <code>int</code>s at the end of the chain.</p>
<p>One frequent challenge with writing unit tests is their linear structure. Again, consider writing a container. Perhaps one of the first things to test is <code>push_back</code>. Next, it may be reasonable to check that <code>erase</code> returns us to where we started. Following this maybe invoke <code>push_back</code> twice. Should we test <code>erase</code> again? And if so back to one element or zero elements, or should we do both? Part of the issue is that the more is done, the more unwieldy the unit test becomes. To alleviate this, <code>sequoia</code> provides a graph-based testing solution defined in <a class="el" href="../../d8/d43/StateTransitionUtilities_8hpp.html">StateTransitionUtilities.hpp</a>. The idea is that nodes corresponds to states of the type under test. Directed edges define transitions between nodes. When invoked, a breadth-first search is performed, invoking specified checks at each node and determining whether the transition from the previous state matches the expected state specified by the latest node. An example may be found in <a class="el" href="../../d7/d13/RegularStateTransitionDiagnostics_8cpp.html">RegularStateTransitionDiagnostics.cpp</a>. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.6
</small></address>
</body>
</html>
